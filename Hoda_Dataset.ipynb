{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Atousa Nasertork-DL-Ex1-Q4.ipynb","provenance":[{"file_id":"1RGw_W4eCS2CDkGYvwPD5VhuwBTCyAa15","timestamp":1600421959512}],"collapsed_sections":[],"mount_file_id":"1zsQVBVpb-Ks2sJR8lrdIT8dhWR11RDeS","authorship_tag":"ABX9TyPWzo+YVdghNWhmUS8Vq0d7"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"0xX9Dvho6ziP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":490},"executionInfo":{"status":"ok","timestamp":1600422177352,"user_tz":-270,"elapsed":2128,"user":{"displayName":"atousa n","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgasGtCWD--Qe32bcBkROLnnOpS3LnxbN_U86POOw=s64","userId":"10426377340166915620"}},"outputId":"cb52362a-0fc8-477c-af10-cd8d40b3cc95"},"source":["!wget https://raw.githubusercontent.com/Alireza-Akhavan/SRU-deeplearning-workshop/master/dataset.py\n","!mkdir dataset\n","!wget https://github.com/Alireza-Akhavan/SRU-deeplearning-workshop/raw/master/dataset/Data_hoda_full.mat -P dataset"],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2020-09-18 09:42:55--  https://raw.githubusercontent.com/Alireza-Akhavan/SRU-deeplearning-workshop/master/dataset.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 929 [text/plain]\n","Saving to: ‘dataset.py’\n","\n","\rdataset.py            0%[                    ]       0  --.-KB/s               \rdataset.py          100%[===================>]     929  --.-KB/s    in 0s      \n","\n","2020-09-18 09:42:55 (35.3 MB/s) - ‘dataset.py’ saved [929/929]\n","\n","--2020-09-18 09:42:56--  https://github.com/Alireza-Akhavan/SRU-deeplearning-workshop/raw/master/dataset/Data_hoda_full.mat\n","Resolving github.com (github.com)... 140.82.113.4\n","Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/Alireza-Akhavan/SRU-deeplearning-workshop/master/dataset/Data_hoda_full.mat [following]\n","--2020-09-18 09:42:56--  https://raw.githubusercontent.com/Alireza-Akhavan/SRU-deeplearning-workshop/master/dataset/Data_hoda_full.mat\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3989009 (3.8M) [application/octet-stream]\n","Saving to: ‘dataset/Data_hoda_full.mat’\n","\n","Data_hoda_full.mat  100%[===================>]   3.80M  16.7MB/s    in 0.2s    \n","\n","2020-09-18 09:42:56 (16.7 MB/s) - ‘dataset/Data_hoda_full.mat’ saved [3989009/3989009]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I3pHPcremVKD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600422855291,"user_tz":-270,"elapsed":1627,"user":{"displayName":"atousa n","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgasGtCWD--Qe32bcBkROLnnOpS3LnxbN_U86POOw=s64","userId":"10426377340166915620"}}},"source":["# import the necessary packages\n","from keras.callbacks import LambdaCallback\n","from keras import backend as K\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tempfile\n","\n","class LearningRateFinder:\n","\tdef __init__(self, model, stopFactor=4, beta=0.98):\n","\t\t# store the model, stop factor, and beta value (for computing\n","\t\t# a smoothed, average loss)\n","\t\tself.model = model\n","\t\tself.stopFactor = stopFactor\n","\t\tself.beta = beta\n","\n","\t\t# initialize our list of learning rates and losses,\n","\t\t# respectively\n","\t\tself.lrs = []\n","\t\tself.losses = []\n","\n","\t\t# initialize our learning rate multiplier, average loss, best\n","\t\t# loss found thus far, current batch number, and weights file\n","\t\tself.lrMult = 1\n","\t\tself.avgLoss = 0\n","\t\tself.bestLoss = 1e9\n","\t\tself.batchNum = 0\n","\t\tself.weightsFile = None\n","\n","\tdef reset(self):\n","\t\t# re-initialize all variables from our constructor\n","\t\tself.lrs = []\n","\t\tself.losses = []\n","\t\tself.lrMult = 1\n","\t\tself.avgLoss = 0\n","\t\tself.bestLoss = 1e9\n","\t\tself.batchNum = 0\n","\t\tself.weightsFile = None\n","\n","\tdef is_data_iter(self, data):\n","\t\t# define the set of class types we will check for\n","\t\titerClasses = [\"NumpyArrayIterator\", \"DirectoryIterator\",\n","\t\t\t \"Iterator\", \"Sequence\"]\n","\n","\t\t# return whether our data is an iterator\n","\t\treturn data.__class__.__name__ in iterClasses\n","\n","\tdef on_batch_end(self, batch, logs):\n","\t\t# grab the current learning rate and add log it to the list of\n","\t\t# learning rates that we've tried\n","\t\tlr = K.get_value(self.model.optimizer.lr)\n","\t\tself.lrs.append(lr)\n","\n","\t\t# grab the loss at the end of this batch, increment the total\n","\t\t# number of batches processed, compute the average average\n","\t\t# loss, smooth it, and update the losses list with the\n","\t\t# smoothed value\n","\t\tl = logs[\"loss\"]\n","\t\tself.batchNum += 1\n","\t\tself.avgLoss = (self.beta * self.avgLoss) + ((1 - self.beta) * l)\n","\t\tsmooth = self.avgLoss / (1 - (self.beta ** self.batchNum))\n","\t\tself.losses.append(smooth)\n","\n","\t\t# compute the maximum loss stopping factor value\n","\t\tstopLoss = self.stopFactor * self.bestLoss\n","\n","\t\t# check to see whether the loss has grown too large\n","\t\tif self.batchNum > 1 and smooth > stopLoss:\n","\t\t\t# stop returning and return from the method\n","\t\t\tself.model.stop_training = True\n","\t\t\treturn\n","\n","\t\t# check to see if the best loss should be updated\n","\t\tif self.batchNum == 1 or smooth < self.bestLoss:\n","\t\t\tself.bestLoss = smooth\n","\n","\t\t# increase the learning rate\n","\t\tlr *= self.lrMult\n","\t\tK.set_value(self.model.optimizer.lr, lr)\n","\n","\tdef find(self, trainData, startLR, endLR, epochs=None,\n","\t\tstepsPerEpoch=None, batchSize=32, sampleSize=2048,\n","\t\tverbose=1):\n","\t\t# reset our class-specific variables\n","\t\tself.reset()\n","\n","\t\t# determine if we are using a data generator or not\n","\t\tuseGen = self.is_data_iter(trainData)\n","\n","\t\t# if we're using a generator and the steps per epoch is not\n","\t\t# supplied, raise an error\n","\t\tif useGen and stepsPerEpoch is None:\n","\t\t\tmsg = \"Using generator without supplying stepsPerEpoch\"\n","\t\t\traise Exception(msg)\n","\n","\t\t# if we're not using a generator then our entire dataset must\n","\t\t# already be in memory\n","\t\telif not useGen:\n","\t\t\t# grab the number of samples in the training data and\n","\t\t\t# then derive the number of steps per epoch\n","\t\t\tnumSamples = len(trainData[0])\n","\t\t\tstepsPerEpoch = np.ceil(numSamples / float(batchSize))\n","\n","\t\t# if no number of training epochs are supplied, compute the\n","\t\t# training epochs based on a default sample size\n","\t\tif epochs is None:\n","\t\t\tepochs = int(np.ceil(sampleSize / float(stepsPerEpoch)))\n","\n","\t\t# compute the total number of batch updates that will take\n","\t\t# place while we are attempting to find a good starting\n","\t\t# learning rate\n","\t\tnumBatchUpdates = epochs * stepsPerEpoch\n","\n","\t\t# derive the learning rate multiplier based on the ending\n","\t\t# learning rate, starting learning rate, and total number of\n","\t\t# batch updates\n","\t\tself.lrMult = (endLR / startLR) ** (1.0 / numBatchUpdates)\n","\n","\t\t# create a temporary file path for the model weights and\n","\t\t# then save the weights (so we can reset the weights when we\n","\t\t# are done)\n","\t\tself.weightsFile = tempfile.mkstemp()[1]\n","\t\tself.model.save_weights(self.weightsFile)\n","\n","\t\t# grab the *original* learning rate (so we can reset it\n","\t\t# later), and then set the *starting* learning rate\n","\t\torigLR = K.get_value(self.model.optimizer.lr)\n","\t\tK.set_value(self.model.optimizer.lr, startLR)\n","\n","\t\t# construct a callback that will be called at the end of each\n","\t\t# batch, enabling us to increase our learning rate as training\n","\t\t# progresses\n","\t\tcallback = LambdaCallback(on_batch_end=lambda batch, logs:\n","\t\t\tself.on_batch_end(batch, logs))\n","\n","\t\t# check to see if we are using a data iterator\n","\t\tif useGen:\n","\t\t\tself.model.fit_generator(\n","\t\t\t\ttrainData,\n","\t\t\t\tsteps_per_epoch=stepsPerEpoch,\n","\t\t\t\tepochs=epochs,\n","\t\t\t\tverbose=verbose,\n","\t\t\t\tcallbacks=[callback])\n","\n","\t\t# otherwise, our entire training data is already in memory\n","\t\telse:\n","\t\t\t# train our model using Keras' fit method\n","\t\t\tself.model.fit(\n","\t\t\t\ttrainData[0], trainData[1],\n","\t\t\t\tbatch_size=batchSize,\n","\t\t\t\tepochs=epochs,\n","\t\t\t\tcallbacks=[callback],\n","\t\t\t\tverbose=verbose)\n","\n","\t\t# restore the original model weights and learning rate\n","\t\tself.model.load_weights(self.weightsFile)\n","\t\tK.set_value(self.model.optimizer.lr, origLR)\n","\n","\tdef plot_loss(self, skipBegin=10, skipEnd=1, title=\"\"):\n","\t\t# grab the learning rate and losses values to plot\n","\t\tlrs = self.lrs[skipBegin:-skipEnd]\n","\t\tlosses = self.losses[skipBegin:-skipEnd]\n","\n","\t\t# plot the learning rate vs. loss\n","\t\tplt.plot(lrs, losses)\n","\t\tplt.xscale(\"log\")\n","\t\tplt.xlabel(\"Learning Rate (Log Scale)\")\n","\t\tplt.ylabel(\"Loss\")\n","\n","\t\t# if the title is not empty, add it to the plot\n","\t\tif title != \"\":\n","\t\t\tplt.title(title)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"sVpUjkUA69Ce","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600422987432,"user_tz":-270,"elapsed":1204,"user":{"displayName":"atousa n","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgasGtCWD--Qe32bcBkROLnnOpS3LnxbN_U86POOw=s64","userId":"10426377340166915620"}}},"source":["# 1. Import libraries and modules\n","import tensorflow as tf\n","import keras\n","from keras import layers\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation\n","import numpy as np\n","from dataset import load_hoda\n","import matplotlib.pyplot as plt\n","\n","np.random.seed(123)  # for reproducibility\n","\n","# Load pre-shuffled HODA data into train and test sets\n","x_train_original, y_train_original, x_test_original, y_test_original = load_hoda(\n","                                                                        training_sample_size=3500,\n","                                                                        test_sample_size=400,size=28)\n","\n","# Preprocess input data\n","''' 3.1: input data in numpy array format'''\n","x_train = np.array(x_train_original)\n","x_test = np.array(x_test_original)\n","'''3.2 normalize our data values to the range [0, 1]'''\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","\n","# Reshape to original image shape (n x 784)  ==> (n x 28 x 28 x 1)\n","x_train = x_train.reshape(-1,28,28,1)\n","x_test = x_test.reshape(-1,28,28,1)\n","\n","\n","# 4. Preprocess class labels\n","y_train = keras.utils.to_categorical(y_train_original, num_classes=10)\n","y_test = keras.utils.to_categorical(y_test_original, num_classes=10)\n","\n","\n","# test and validation set\n","x_val = x_test[:200]\n","x_test = x_test[200:]\n","y_val = y_test[:200]\n","y_test = y_test[200:]\n","\n","# 5. Define model architecture\n","model = Sequential()\n","model.add(layers.Conv2D(32, (3, 3), activation='relu',\n","                        input_shape=(28, 28, 1)))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","model.add(layers.Flatten())\n","model.add(layers.Dense(64, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(layers.Dense(10, activation='softmax'))\n","\n","MIN_LR = 1e-5\n","opt = tf.keras.optimizers.SGD(lr=MIN_LR, momentum=0.9)\n","\n","# 6. Compile model\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"qra-5n-RNTNG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":922},"executionInfo":{"status":"ok","timestamp":1600426569168,"user_tz":-270,"elapsed":67698,"user":{"displayName":"atousa n","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgasGtCWD--Qe32bcBkROLnnOpS3LnxbN_U86POOw=s64","userId":"10426377340166915620"}},"outputId":"5de92f7e-6ed1-4be6-e466-8437b2b40fbe"},"source":["# initialize the learning rate finder and then train with learning\n","# rates ranging from 1e-10 to 1e+1\n","lrf = LearningRateFinder(model)\n","lrf.find((x_train, y_train),1e-10, 4e-1)\n","# plot the loss for the various learning rates and save the\n","# resulting plot to disk\n","lrf.plot_loss()"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Epoch 1/19\n","110/110 [==============================] - 3s 31ms/step - loss: 2.3208 - accuracy: 0.1049\n","Epoch 2/19\n","110/110 [==============================] - 3s 31ms/step - loss: 2.3235 - accuracy: 0.1086\n","Epoch 3/19\n","110/110 [==============================] - 3s 32ms/step - loss: 2.3234 - accuracy: 0.1103\n","Epoch 4/19\n","110/110 [==============================] - 3s 32ms/step - loss: 2.3220 - accuracy: 0.1094\n","Epoch 5/19\n","110/110 [==============================] - 4s 32ms/step - loss: 2.3225 - accuracy: 0.1086\n","Epoch 6/19\n","110/110 [==============================] - 3s 32ms/step - loss: 2.3230 - accuracy: 0.1083\n","Epoch 7/19\n","110/110 [==============================] - 3s 31ms/step - loss: 2.3232 - accuracy: 0.1071\n","Epoch 8/19\n","110/110 [==============================] - 3s 31ms/step - loss: 2.3249 - accuracy: 0.1077\n","Epoch 9/19\n","110/110 [==============================] - 3s 31ms/step - loss: 2.3226 - accuracy: 0.1077\n","Epoch 10/19\n","110/110 [==============================] - 3s 32ms/step - loss: 2.3227 - accuracy: 0.1089\n","Epoch 11/19\n","110/110 [==============================] - 4s 32ms/step - loss: 2.3222 - accuracy: 0.1094\n","Epoch 12/19\n","110/110 [==============================] - 3s 31ms/step - loss: 2.3205 - accuracy: 0.1091\n","Epoch 13/19\n","110/110 [==============================] - 3s 31ms/step - loss: 2.3142 - accuracy: 0.1097\n","Epoch 14/19\n","110/110 [==============================] - 3s 31ms/step - loss: 2.2993 - accuracy: 0.1194\n","Epoch 15/19\n","110/110 [==============================] - 3s 31ms/step - loss: 2.2114 - accuracy: 0.2086\n","Epoch 16/19\n","110/110 [==============================] - 3s 31ms/step - loss: 1.1958 - accuracy: 0.5949\n","Epoch 17/19\n","110/110 [==============================] - 3s 31ms/step - loss: 0.5584 - accuracy: 0.8146\n","Epoch 18/19\n","110/110 [==============================] - 3s 31ms/step - loss: 0.6006 - accuracy: 0.7977\n","Epoch 19/19\n","110/110 [==============================] - 3s 31ms/step - loss: 2.8798 - accuracy: 0.2857\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5xdZX3v8c9vX+Z+TWbIJJMrEYREIMgYQKhCqwhWRSsqaBEVm6PV09paq+05FS/tac/LU9t6Rap4F1TEFhUvtKKgXGSCAUkIEMIlCQmZZJK5z+zb7/yx1oTNsCeZSWbt23zfr9d+zd7Puv3Wzs7+7ed51noec3dERESmipU6ABERKU9KECIiUpAShIiIFKQEISIiBSlBiIhIQUoQIiJSUKLUAcyljo4OX7lyZanDEBGpGBs3btzn7p2FllVVgli5ciW9vb2lDkNEpGKY2RPTLVMTk4iIFKQEISIiBSlBiIhIQUoQIiJSkBKEiIgUpAQhIiIFKUGIiFSwLU8N8suH+yLZtxKEiEgF+8bdT/D+79wXyb6VIEREpKDIEoSZLTOzW81si5ltNrM/L7DOeWY2YGabwseH85ZdaGYPmdk2M/tQVHGKiEhhUQ61kQHe7+73mlkzsNHMbnH3LVPWu93dX5VfYGZx4LPAy4GdwD1mdlOBbUVEJCKR1SDcfbe73xs+HwIeBLpnuPl6YJu7b3f3FHA9cHE0kYqISCFF6YMws5XA6cDdBRafbWb3mdmPzWxtWNYN7MhbZyfTJBcz22BmvWbW29cXTU++iMh8FHmCMLMm4HvA+9x9cMrie4EV7n4a8GngP2a7f3e/xt173L2ns7PgiLUiInIUIk0QZpYkSA7fdPcbpy5390F3Hw6f3wwkzawD2AUsy1t1aVgmIiJFEuVVTAZ8CXjQ3T85zTpd4XqY2fownv3APcAJZrbKzGqAS4GboopVRESeK8qrmM4BLgd+Z2abwrK/BZYDuPvVwCXAu80sA4wBl7q7Axkzey/wUyAOXOvumyOMVUREpogsQbj7rwA7wjqfAT4zzbKbgZsjCE1ERGZAd1KLiEhBShAiIlKQEoSIiBSkBCEiIgUpQYiISEFKECIiUpAShIiIFKQEISIiBSlBiIhIQUoQIiJSUJRjMcksjKWyPD04zkgqw0QmB0DMjJgFf90h607OHXcn50F5S12C41rqaK1PlvgMnpHLOZmck8056VyObDb8G5blcpDJ5ci5k81BOpujb3iCmBmjExlGU1lG01nGUhlyDrWJGHXJOHXJGPXJOK31NbTWJ2lrCB7xmDEwlubgaJpFzXW0NpTmvXAPzjuVyeFAMm7UxGOE41EeUTbnbHlqkIeeHmIsnT1UPnXryd3FzGisTdBcm6CxNkFtIsZYOksu59QmY7TWJ2mpT9Jan6Q2EZ+bk5R5RQniKLk7B0fT7B+ZoDYRp60hyd6hCZ4eGGfPYPB4emCcpwcnGEtnyeacTPglmc56+NrJ5nKMTGTZdXDsqGNJxIyTFjezuLWeRS21NNYmyGaD/aezOTLh80wueJ7OhnHknEy4fHA8zf6RFG31SVYsbGDFwkZa6pIkE0bcLNg+G+5jcrvwC39wLM29Tx5k79A4qUyOnM/hG30UlrTWcdLiFk7qaqartY7mugQNNQliZhjBF2wm54xMZBieyDA0ngGgu62elR2NNNTEGZ7IMDCa5sBoigOjaQ6Opg49Hx7PMJ7OMp7OMpbOMp7OMZbOMjyeedYX+6SaRIzaeIyaRN4j73UiZqQyOZ4aGKdvaCKS96QuGaOlLklzXYLm8G9dMk795KMmTlNtgq7WOuqScZJxozYRIxnGmYzHwh8qjgPuEDOIx+zQI2bGvuEJ9g+ncILE1liboKU+wcLGWhY21dDeUEM8NrOEKaWnBBFyd/YMjjM0niGdzXFgJM2+4Qn2DU/QNzzBvqHUodeT/wkyR/gmbK5L0NVSR0NtgkTMSMSMmkSM+prgSyEeC75865IxLu1cxpK2+uCXYDKGEfwnDH5le1CbiE3WKoJHOpdjaDzD5qcG2Lp7iB39o/Q+3s9IKksyZiTiwXEScSMRi5GMB8dMxmPPKVvaXs+6ZW3sH0nx5P5RfrVtH+Pp3HPOKWaQiAXbT+4rGTfWLWvjwhd0UXNo30Y83H8iZsTDWOKW94USvicxM5pqE9TXxKhPJmioiQeP2gQxg4l0jvFM8EU8MpFhcCwd1BjCWkPOncaaOAubatl1cIytuwd5cPcQtz3cd8R/o5mKGbQ11NDWkKS5NvhybWuoYXFYs6lLxmmsTdBWnySZCP790tkcqUyOifDvoUf22c8zWaexMcHKjkbOf/5xnLq0lea6Z2pBwVfyoReHZHLOaCrD8MQzyamxJk4sZoynswyE79PAaPB3aDxIiIPjaYYnMuwbTgVJLhUkuuGJDNmIs7sZLGioYWFTDQsaa1jYVEtH+HdRSy0nLmrmhEXNNNXqq6kczPt/hUw2xxu/cCePPD3M0ESm4DrJuNHRVEtHUy2LWupYu6Tl0OuFTTWMpYL/jMe1BMu7Wuroaq2joaY4b+9rTlsSyX6zYQ0k5x4khfBLvdgaao5uu3Q2x8BYmsGxNKOpLO7Bl6178Mu3qTZBU13i0JfRk/2jPLF/lIlMlsbaBK31SdobamhvSNJSlyzJuRdTOpujfyQVJLUwgaWzzyS0nAc/VCabuNyDz0jWnVxYm2ypT9LVUkfMjJw7I6kMA2Np+kdS7B9OsX8kxf7wB9b+kQkefGqQfcMTDI4/+//e4tY6elYuYP2qBZx9/AJWdzbNuKlO5s68TxCJeIzFbfW8oLuVExY1syCsArc1JOloqqWzqZaW+sS8/HAGv/Qrt+06GY8dSuQzceKiZk5c1BxxVOUrGY+xqKWuJMdOZXLsHhhj654hHu0bZstTg/zmsf384L6nAOhsruWs4xdy9vELOXv1QlYubJiX/yeLbd4nCIDPvvmFpQ5BZF6rScRYsbCRFQsbD5W5O0/2j3Lno/u5c/t+7nz0mYTR1VLH2asX8rKTF/GyNcfN6074YI61aESWIMxsGfA1YBFBy+k17v5vU9Z5C/BBgv6sIeDd7n5fuOzxsCwLZNy9J6pYRaT8mNmhpHHp+uW4O9v3jRxKGLc93Mf3f7uLtoYkl7xwKVf+3ioWt9aXOuyiOziapi2iK/eirEFkgPe7+71m1gxsNLNb3H1L3jqPAS919wNmdhFwDXBm3vLz3X1fhDGKSIUwM1Z3NrG6s4k/PmsF2Zzz6237+HbvDr58x+N89c7HuWz9cj7wiuc/q5O/2vUNTdA5w2bU2YpyytHdwO7w+ZCZPQh0A1vy1rkjb5O7gKVRxSMi1SUeM15yYicvObGTHf2jXP3LR/nGXU+QzTn/8LpTSh1e0fQNT3Dq0rZI9l2UO6nNbCVwOnD3YVa7Evhx3msHfmZmG81sw2H2vcHMes2st6+vby7CFZEKs2xBA//wulN47end3LTpKcYL3I9SrfZFWIOIPEGYWRPwPeB97j44zTrnEySID+YVn+vuLwQuAt5jZi8ptK27X+PuPe7e09nZOcfRi0glueSMpQxNZPjZlqdLHUpRjKWyjKSydDQf5bXgRxBpgjCzJEFy+Ka73zjNOqcCXwQudvf9k+Xuviv8uxf4PrA+ylhFpPKdtWoh3W31/Odvd5U6lKLoH00BsLCxwhKEBRcpfwl40N0/Oc06y4Ebgcvd/eG88sawYxszawQuAB6IKlYRqQ6xmPHyNYu449H986KZ6cBIkCDaj/Zu0iOIsgZxDnA58Ptmtil8vNLM3mVm7wrX+TCwEPhcuLw3LF8E/MrM7gN+A/zI3X8SYawiUiVeemInY+ksvY8fKHUokesPE8SCiGoQUV7F9CueOxDl1HXeCbyzQPl24LSIQhORKnbm8QuoScT4xUN7OfeEjlKHE6kDYRNTe6U1MYmIlEJDTYIzVy3glw9X/1WN/RXcxCQiUhJnr17II3uH2T8czfDp5eLASAozIpsPRglCRKrOi1YuAGDjE9XdD9E/GszhEtUcG0oQIlJ1TulupSYeo7fKE8SBkXRk/Q+gBCEiVaguGefUpa3c83h/qUOJVP9IigUR9T+AEoSIVKkzVrbzwK4BJjLVez/EgdGUahAiIrN12tI20lnnoT1DpQ4lMgdGVYMQEZm1U7pbAbh/50CJI4mGu6sPQkTkaCxtr2dBYw337zxY6lAiMZLKksrmWNAY3dwXShAiUpXMjFO6W6u2BhH1OEygBCEiVezUpa08sneYsVT1dVRHfRc1KEGISBU7dWkb2ZyzZXfBqWgq2sBYGiCy+ahBCUJEqtipSyc7qquvH2JwPEgQLRENswFKECJSxRa11HFcc21V9kMMjmUAaKlTghAROSqndLey+akqTBCHahCRzdqgBCEi1W3tkhYe7RupuhnmBsfSJGJGfTIe2TGinHJ0mZndamZbzGyzmf15gXXMzD5lZtvM7H4ze2HesivM7JHwcUVUcYpIdVuzpJVsztlaZXdUD4ylaa1PEszuHI0oaxAZ4P3uvgY4C3iPma2Zss5FwAnhYwPweQAzWwBcBZwJrAeuMrP2CGMVkSq1dkkLQNU1Mw2OZyLtoIYIE4S773b3e8PnQ8CDQPeU1S4GvuaBu4A2M1sMvAK4xd373f0AcAtwYVSxikj1WtpeT2t9ks1PVdelroNjaVrqout/gCL1QZjZSuB04O4pi7qBHXmvd4Zl05UX2vcGM+s1s96+vuqfYlBEZsfMWLO4pfoSxHi6cmsQk8ysCfge8D53n/N/IXe/xt173L2ns7NzrncvIlVg7ZIWtu4eJJPNlTqUORPUICo4QZhZkiA5fNPdbyywyi5gWd7rpWHZdOUiIrO2ZkkLE5kc2/eNlDqUORP0QVRoE5MFXetfAh50909Os9pNwFvDq5nOAgbcfTfwU+ACM2sPO6cvCMtERGZt7ZLgjupq6qguRg0iyvRzDnA58Dsz2xSW/S2wHMDdrwZuBl4JbANGgbeHy/rN7OPAPeF2H3P36p47UEQis7qzkdpEjM27Bnnd6aWO5tiNp7NMZHKR90FEliDc/VfAYS/QdXcH3jPNsmuBayMITUTmmUQ8xkldzVXTUT00PjnMRoU2MYmIlJM1S4IhN4LfpZVtciTXir+KSUSkHKxd0sLgeIadB8ZKHcoxOzQOUyVfxSQiUi4m76iuhrkhJpuYmtXEJCJy7E7qaiFmVEU/xMhEkCAaa5UgRESOWX1NnNWdTWypgktdh8ME0aQEISIyN9YuqY4hN1SDEBGZY2uXtLJ7YJz+kVSpQzkmzySI6OaCACUIEZlHqmXo7+GJLMm4UZtQghARmRNrDiWIym5mGpnIRN7/AEoQIjKPtDXU0N1WXxUJIur+B1CCEJF5Zs2SlipoYlINQkRkzq1d0sJj+0YOdfRWopGUahAiInNu7ZJW3GHrnsptZhqeyCpBiIjMtbVV0FEddFJHewUTKEGIyDyzuLWO9oYkm3dVdoJorFENQkRkTpkZa5e0snl35XZUD1f6VUxmdq2Z7TWzB6ZZ/gEz2xQ+HjCzrJktCJc9bma/C5f1RhWjiMxPa5e08PCeYdLZXKlDmTV3r4r7IL4CXDjdQnf/hLuvc/d1wN8Av5wyrej54fKeCGMUkXlozZIWUtkcjzw9XOpQZm08nSPn0Y/DBBEmCHe/DZjpPNKXAddFFYuISL61S1qBypwb4pmRXOdBJ7WZNRDUNL6XV+zAz8xso5ltOML2G8ys18x6+/r6ogxVRKrEqo5G6pPxirxhrlgjuUIZJAjg1cCvpzQvnevuLwQuAt5jZi+ZbmN3v8bde9y9p7OzM+pYRaQKxGPGyYubK/JS1+F5liAuZUrzkrvvCv/uBb4PrC9BXCJSxdYuaeXBpwbJ5bzUoczKSJEmC4ISJwgzawVeCvxnXlmjmTVPPgcuAApeCSUicrTWLmlhaCLDjgOjpQ5lVkZTWaA4NYjIjmBm1wHnAR1mthO4CkgCuPvV4WqvA37m7iN5my4Cvm9mk/F9y91/ElWcIjI/vaA76Ki+f+cAKxY2ljiamZtMEA010XdSR5Yg3P2yGazzFYLLYfPLtgOnRROViEjg+V3N1CZibNpxkFeftqTU4czYaCpoYqpPzoOrmERESiEZj3FKdyubdhwsdSizMp4OahD1RahBKEGIyLy1blkbD+waqKg7qovZxKQEISLz1rrlbUxkcmzdPVTqUGZsLKxB1EU8HzUoQYjIPLZuWRsAm3YcKHEkMzeWylKXjBGLWeTHUoIQkXmru62ejqZafltB/RBj6WxROqhhhgkivDchFj4/0cxeY2bJaEMTEYmWmbFuWVtFdVSPpsosQQC3AXVm1g38DLicKZeniohUotOXt7G9b4SB0XSpQ5mRsXS2KFcwwcwThLn7KPBHwOfc/Q3A2ujCEhEpjsl+iPt2VkYtYixVhgnCzM4G3gL8KCwrToQiIhE6dWkrZlRMM9NYKktDMvphNmDmCeJ9BJP6fN/dN5vZ8cCt0YUlIlIczXVJntfZVDEJYjSdpa5INYgZpSF3/yXwS4Cws3qfu/9ZlIGJiBTLumVt/PfWvbg74ThwZWs8lWVxS11RjjXTq5i+ZWYt4eiqDwBbzOwD0YYmIlIc65a30T+SYkf/WKlDOaLRdKbs+iDWuPsg8Frgx8AqgiuZREQq3unL2gH4bQXcMDeWypVdgkiG9z28FrjJ3dME04KKiFS8Exc10VgTp/fxSkgQmbK7D+ILwONAI3Cbma0AKm+uPhGRAhLxGKcvb6f3ifJOEO7OWDpblIH6YIYJwt0/5e7d7v5KDzwBnB9xbCIiRXPGinYe2jPI0Hj53jA3kcmRc6grpxqEmbWa2SfNrDd8/DNBbeJw21xrZnvNrOB0oWZ2npkNmNmm8PHhvGUXmtlDZrbNzD40qzMSETkKPSvbyTn89snyvdx1ci6IsqpBANcCQ8Abw8cg8OUjbPMV4MIjrHO7u68LHx8DMLM48FngImANcJmZrZlhnCIiR+X05e3EjLJuZpqcC6JYfRAzvR1vtbu/Pu/1R81s0+E2cPfbzGzlUcS0HtgWTj2KmV0PXAxsOYp9iYjMSFNtgpO6Wtj4RH+pQ5nWWBFnk4OZ1yDGzOzcyRdmdg4wFxcMn21m95nZj81scmynbmBH3jo7w7KCzGzDZNNXX1/fHIQkIvPVmiUtPLp3pNRhTGusTGsQ7wK+Zmat4esDwBXHeOx7gRXuPmxmrwT+Azhhtjtx92uAawB6enp06a2IHLXFrXX0DU+QyeZIxMtvupyyrEG4+33ufhpwKnCqu58O/P6xHNjdB919OHx+M8G9Fh3ALmBZ3qpLwzIRkUh1tdaRzTn7hlOlDqWgYs5HDbOcUS78Up+8/+Evj+XAZtZl4aAnZrY+jGU/cA9wgpmtMrMa4FLgpmM5lojITHSFYxztHijPITcmm5iKdZnrsYwZe9gRrczsOuA8oMPMdgJXAUkAd78auAR4t5llCPozLnV3BzJm9l7gpwRDil/r7puPIU4RkRnpag0SxNOD4yWOpLDJy1wrIUEctr3f3S87wvLPAJ+ZZtnNwM1HH5qIyOwtbq0HYPdAeSaIiUwZJQgzG6JwIjCgPpKIRERKpL0hSU0ixp4yTRDj6RwAdYnidKAfNkG4e3NRohARKQNmRldLXdnXIGrLaagNEZH5oqu1jj1l2wdR3BqEEoSISJ6ulrqybWKayGSJx6xo92goQYiI5Fkc1iCCiyrLy3g6V7TaAyhBiIg8S1drHalMjgOj5Tfs90QmW7T+B1CCEBF5lnK+WU41CBGREpq8Wa4c+yEmMjnVIERESqWcb5YbT2epVQ1CRKQ0OppqiFl5DrehGoSISAkl4jGOay7Pm+XG01n1QYiIlFJXa3neC6EahIhIiS1pq+Opg+V3FdOEahAiIqW1tL2BnQfHyOXK62Y51SBEREpsaXs9qUyOfcMTpQ7lWdQHISJSYkvbg0tdd5ZZM1NQg6iCBGFm15rZXjN7YJrlbzGz+83sd2Z2h5mdlrfs8bB8k5n1RhWjiEgh3W0NAOw8UGYJIp2lLlEdTUxfAS48zPLHgJe6+ynAx4Frpiw/393XuXtPRPGJiBTUPVmDODBa4kiebbzINYhjmXL0sNz9NjNbeZjld+S9vAtYGlUsIiKz0VSboL0hya4yqkFksjmyOa+aGsRsXAn8OO+1Az8zs41mtuFwG5rZBjPrNbPevr6+SIMUkfmju72+rJqYxjPBZEFVUYOYKTM7nyBBnJtXfK677zKz44BbzGyru99WaHt3v4aweaqnp6e8rkkTkYq1tK2BR/YOlTqMQybS4XSj86UGYWanAl8ELnb3/ZPl7r4r/LsX+D6wvjQRish8tbS9nl0Hx8pm4qDJGkRdNVzFdCRmthy4Ebjc3R/OK280s+bJ58AFQMEroUREorK0vZ7xdI79I6lShwKUpgYRWROTmV0HnAd0mNlO4CogCeDuVwMfBhYCnzMzgEx4xdIi4PthWQL4lrv/JKo4RUQK6W5/5lLXjqbaEkcTTBYExa1BRHkV02VHWP5O4J0FyrcDpz13CxGR4lmad6nrumVtJY4mmG4U5lEfhIhIuVq2IKhBPLG/PO6FmKxBVMWd1CIilaypNsFxzbU8vm+k1KEAqkGIiJSVlR2NPFYmCaIUfRBKECIi0zi+jBKEahAiImVkVUcj+0dSDIylSx0KE5N3Umu4bxGR0lvZ0QhQFv0QKSUIEZHycXyYIMqhmWkyQdQoQYiIlN7yhQ2YwfZySBBZJQgRkbJRm4jT3VZfVk1MNXElCBGRsrCqo5Ht+4ZLHQbpbA4ziMesaMdUghAROYzVnU1s7xshlyvtqK6pTI6aeIxwnLqiUIIQETmM53c1M5rKsutgaScPmsjkitr/AEoQIiKHdeKiZgAe2lPayYPS2VxRL3EFJQgRkcM6cVETAA89XdoEkcrkSBaxgxqUIEREDqu5Lkl3Wz0PlzpBZNXEJCJSdk5c1FTyJqbJTupiivRoZnatme01s4JThlrgU2a2zczuN7MX5i27wsweCR9XRBmniMjhnNjVzPa+ETLhzWqlkK7CGsRXgAsPs/wi4ITwsQH4PICZLSCYovRMYD1wlZm1RxqpiMg0nr+omVQ2x+MlnDxootr6INz9NqD/MKtcDHzNA3cBbWa2GHgFcIu797v7AeAWDp9oREQiUw5XMqXm4WWu3cCOvNc7w7Lpyp/DzDaYWa+Z9fb19UUWqIjMXycsaiIZNx54aqBkMaR0mevsufs17t7j7j2dnZ2lDkdEqlBtIs5JXS38bmfpEkQ6W2Wd1DOwC1iW93ppWDZduYhISZyytJX7dx7EvTRDbszH+yBuAt4aXs10FjDg7ruBnwIXmFl72Dl9QVgmIlISp3a3Mjie4cn+0nRUl6IPIhHlzs3sOuA8oMPMdhJcmZQEcPergZuBVwLbgFHg7eGyfjP7OHBPuKuPufvhOrtFRCL1gu5WAO7fOcCKhY1FP37VJQh3v+wIyx14zzTLrgWujSIuEZHZOnFRMzWJGL/bNcCrT1tS9OOnsj7vrmISEakINYkYJy9u4f6dB0ty/FQmO+86qUVEKsap3a08sGuQbAnmhtBYTCIiZeyFK9oYnsiwdc9g0Y+dzrpqECIi5Wr9qoUA3PNYca+ZyeacbE59ECIiZau7rZ7utnruefxAUY+bygSDBM63+yBERCrK+lULuPux/qLeMDeZIFSDEBEpYy9auYB9wxNFHdk1lVWCEBEpe+tXBTMP/Oax/UU75mSCqFUTk4hI+Vrd2cRxzbXc9si+oh3zUB9Ewop2TFCCEBGZFTPjpSd2cvvDfUWbYe5QH0Q8XpTjTVKCEBGZpfNPOo7B8QybdhTnruq0+iBERCrDOc/rIB4zbn1ob1GON6GrmEREKkNrfZIzVrTz3w8WJ0E8cx+E+iBERMreK9Z2sXXPENv7hiM/1qGrmFSDEBEpf688pQuAm3+3O/JjpdVJLSJSORa31tOzop0f3h99gqjKG+XM7EIze8jMtpnZhwos/xcz2xQ+Hjazg3nLsnnLbooyThGRo/GHpy5m654htu0divQ4VdcHYWZx4LPARcAa4DIzW5O/jrv/hbuvc/d1wKeBG/MWj00uc/fXRBWniMjR+sNTFhOPGd/t3RnpcaqxBrEe2Obu2909BVwPXHyY9S8DroswHhGROXVcSx0vP3kR3924k4lMNrLjVONgfd3AjrzXO8Oy5zCzFcAq4Od5xXVm1mtmd5nZa6c7iJltCNfr7evrm4u4RURm7C1nLad/JMVPHtgT2TEmE0TtPO2kvhS4wd3zU/AKd+8B3gz8q5mtLrShu1/j7j3u3tPZ2VmMWEVEDjlndQfLFzTwzbufjOwYk01M1TQW0y5gWd7rpWFZIZcypXnJ3XeFf7cDvwBOn/sQRUSOTSxmvOXM5fzmsX4e2DUQyTGeucy1epqY7gFOMLNVZlZDkASeczWSmZ0EtAN35pW1m1lt+LwDOAfYEmGsIiJH7bIzl9NSl+DTP38kkv2nsjliBolqSRDungHeC/wUeBD4jrtvNrOPmVn+VUmXAtf7s6dnOhnoNbP7gFuBf3J3JQgRKUstdUneds4qfrr5abY8NTjn+09lckXvoAZIRLlzd78ZuHlK2YenvP5Ige3uAE6JMjYRkbn0jnNW8tU7HuejP9jM9RvOwmzu+gvG01lqE8XtoIby6aQWEalobQ01fOiik7j7sf45vy+ifzRNe0NyTvc5E0oQIiJz5E09y1i3rI3P3LptTicT2j88wYLGmjnb30wpQYiIzJFYzHj3eat5sn+Ud33jXkZTmTnZ757Bcbpa6+ZkX7OhBCEiModesbaLj75mLT/f+jRv+sJd7B0cP6b9uTt7BsbpaqmfowhnTglCRGSOXfHilfz7W3t4tG+Y133uDnYdHDvqfQ2OZxhNZVmsGoSISHX4g5MX8e0NZzM4nuaPv3j3UdckdvSPArCkTTUIEZGqccrSVr7y9hfx9OA4b/zCnUdVk5i8r+Lkxc1zHd4RKUGIiETojBUL+PqVZ7J/JMUbPn8H2/bOborS+3YepLEmzsqFjRFFOD0lCBGRiJ2xop3r/uQsUtkcb6+FtmQAAApcSURBVLj6Dn775IEZbTeeznLLlqc5e3UHsVhxB+oDJQgRkaJ4QXcrN7zrxTTXJXnzv9/NLx7ae9j1R1MZ3nf9JvYOTfCOc1YWJ8gpIh1qQ0REnrGyo5Eb3n02b7v2Ht751V7+9LzVvGn9crrzOqA/ecvDPLh7kG17h3l8/wh/96o1vPh5HSWJ1549Rl5l6+np8d7e3lKHISJyWEPjaf76hvv5cTjJ0NL2elYsbGD/cIqte4L5rU9f3sb7X/58zj0h2uRgZhvDuXeeQzUIEZEia65L8vk/PoPH9o1w69a9bHzyALsOjNHeUMP/euXJXH72CuqSxR+cbyolCBGRElnV0ciqc1fxDlaVOpSC1EktIiIFKUGIiEhBkSYIM7vQzB4ys21m9qECy99mZn1mtil8vDNv2RVm9kj4uCLKOEVE5Lki64MwszjwWeDlwE7gHjO7qcDUod929/dO2XYBcBXQAziwMdx2ZneXiIjIMYuyBrEe2Obu2909BVwPXDzDbV8B3OLu/WFSuAW4MKI4RUSkgCgTRDewI+/1zrBsqteb2f1mdoOZLZvltpjZBjPrNbPevr6+uYhbREQofSf1D4CV7n4qQS3hq7Pdgbtf4+497t7T2dk55wGKiMxXUSaIXcCyvNdLw7JD3H2/u0+EL78InDHTbUVEJFqRDbVhZgngYeAPCL7c7wHe7O6b89ZZ7O67w+evAz7o7meFndQbgReGq94LnOHu/Uc4Zh/wxJyfTPQ6gH2lDqKE5vv5g96D+X7+ULr3YIW7F2x+iewqJnfPmNl7gZ8CceBad99sZh8Det39JuDPzOw1QAboB94WbttvZh8nSCoAHztScgi3q8g2JjPrnW4slPlgvp8/6D2Y7+cP5fkeVNVgfZWqHD8YxTTfzx/0Hsz384fyfA9K3UktIiJlSgmiPFxT6gBKbL6fP+g9mO/nD2X4HqiJSUREClINQkREClKCEBGRgpQgRESkICWIMmZma8zsO2b2eTO7pNTxlIKZ/Z6ZXW1mXzSzO0odT7GZ2Xlmdnv4HpxX6nhKwcxODs//BjN7d6njKTYzO97MvmRmNxT72EoQETGza81sr5k9MKX8sHNkTHER8Gl3fzfw1siCjchcvAfufru7vwv4IUcxVlcpzdFnwIFhoI5g0MqKMkefgQfDz8AbgXOijHeuzdH5b3f3K6ONtDBdxRQRM3sJwX/sr7n7C8KyOMHwI4fmyAAuI7jT/B+n7OId4d+rgFHgxe5eaf85jvk9cPe94XbfAa5096EihX/M5ugzsM/dc2a2CPiku7+lWPHPhbn6DIQjLrwb+Lq7f6tY8R+rOf4/cIO7F7UlIbKhNuY7d7/NzFZOKT40RwaAmV0PXOzu/wi8appdvSf8QN0YVaxRmav3wMyWAwOVlBxgTj8DAAeA2ijijNJcvQfh0Dw3mdmPgIpJEHP8GSg6JYjiKjTPxZnTrRx+sP4WaAQ+EWVgRTSr9yB0JfDlyCIqrtl+Bv6IYAKtNuAz0YZWNLN9D84D/oggQd4caWTFMdvzXwj8A3C6mf1NmEiKQgmijLn748CGUsdRau5+ValjKBV3v5EKrD3OJXf/BfCLEodRMu6+H3hXKY6tTuri0jwXeg/m+/mD3oOKOX8liOK6BzjBzFaZWQ1wKXBTiWMqtvn+Hsz38we9BxVz/koQETGz64A7geeb2U4zu9LdM8DkHBkPAt/Jn0Cp2sz392C+nz/oPaj089dlriIiUpBqECIiUpAShIiIFKQEISIiBSlBiIhIQUoQIiJSkBKEiIgUpAQhRWNmw0U+3pzMHxHOyTBgZpvMbKuZ/b8ZbPNaM1tzFMd6rZl9OHz+ETP7q6OJ+TD7P8vM7g7P5UEz+8hR7ucXZtZzhHWuN7MTjipQKQtKEFKxzOywY4m5+4vn8HC3u/s64HTgVWZ2pKHXXwvMOkEAfw187ii2m6mvAhvCc3kB8J0Ij/V5gvORCqUEISVlZqvN7CdmttGCmdNOCstfHf7S/a2Z/Vc4H8Lkr+qvm9mvga+Hr68Nf9FuN7M/y9v3cPj3vHD5DWEN4JtmZuGyV4ZlG83sU2b2w8PF6+5jwCaCETkxsz8xs3vM7D4z+56ZNZjZi4HXAJ8If6mvnu48p7wXJwIT7r7vMO+XmdknzOwBM/udmb0pLI+Z2efCc7nFzG62wrMQHgfsDs8l6+5bwu2bzOzL4T7vN7PXh+WfN7NeM9tsZh+dJqYLzOxOM7vXzL5rZk3hotuBlx0pkUsZc3c99CjKAxguUPbfwAnh8zOBn4fP23nmTv93Av8cPv8IsBGoz3t9B8FQ0B3AfiCZfzzgPGCAYFC0GMHQB+cSzNK2A1gVrncd8MMCMZ43WR7GtRHoCl8vzFvv74H/GT7/CnDJkc5zynHePnmeeef2V1PWeT1wC8HkMouAJ4HFwCUEQ2HHgC6C+SMuKXCMD4fLvg/8D6AuLP+/wL/mrdce/l0Q/o0TjKh6avj6F0BP+J7fBjSG5R8EPpy3n1uAM0r92dPj6B7K7FIy4S/NFwPfDX/QwzOT4iwFvm1mi4Ea4LG8TW/y4Jf8pB+5+wQwYWZ7Cb44p07P+Rt33xkedxOwkmCmr+3uPrnv65h+ePXfM7P7gBMIvkj3hOUvMLO/J5ivoYlgfJ3ZnGe+xUDfNMefdC5wnbtngafN7JfAi8Ly77p7DthjZrcW2tjdP2Zm3wQuAN5MMJPZecDLCAaNm1zvQPj0jWa2gWBqgMUEzWb35+3yrLDs1+G51RAk4El7gSUESVUqjBKElFIMOOhBe/hUnyaYYvMmCyaM+UjespEp607kPc9S+HM9k3UO53Z3f5WZrQLuMrPvuPsmgprCa939PjN7G8GX7VSHO898Y0DrLOOaNXd/FPi8mf070GfBhDTPEZ7rXwEvcvcDZvYVglrXs1YDbnH3y6Y5XB3BeUkFUh+ElIy7DwKPmdkb4FD7+mnh4laeGSP/iohCeAg43p6ZEvJNR9ogrG38E0FTCkAzsNvMkkD+fNFD4bIjnWe+B4HnHSGE24E3mVnczDqBlwC/AX4NvD7si1hE4USFmf3hZP8LQW0oCxwkaAp6T9567UALQTIeCPd5UYFd3gWcY2bPC7drDPtSJp0IPHCEc5IypQQhxdRgwZDHk4+/JPhSvTJsvtkMXByu+xGCJpmNwLSdtscibKb6U+An4XGGCPoqjuRq4CVhYvk74G6CL+iteetcD3wg7GRfzfTnme82gmklLa/sf+e/ZwR9B/cD9wE/B/46bO76HkGz2hbgG8C905zL5cBDYTPb14G3hM1Vfw+0h53f9wHnu/t9wG/D8/pWeI7P4u59wNuA68zsfoLmpckLDRYBY3nNcVJhNNy3zGtm1uTuw+GX8meBR9z9X0oYz78BP3D3/zqKbSfPZSFBreKcUn45m9lfAIPu/qVSxSDHRjUIme/+JPw1vZmgWesLJY7n/wANR7ntD8NzuR34eBn8cj9IcN+FVCjVIEREpCDVIEREpCAlCBERKUgJQkREClKCEBGRgpQgRESkICUIEREp6P8Dt/PEZupDudYAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"HOzX-27onZbb","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}
