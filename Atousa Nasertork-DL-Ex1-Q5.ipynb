{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Atousa Nasertork-DL-Ex1-Q5.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOFkEkB2KOEkiNy1MndoLS+"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"e8Fxl-R6N4X2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":470},"executionInfo":{"status":"ok","timestamp":1600416643248,"user_tz":-270,"elapsed":2036,"user":{"displayName":"atousa n","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgasGtCWD--Qe32bcBkROLnnOpS3LnxbN_U86POOw=s64","userId":"10426377340166915620"}},"outputId":"24a7e3e0-93e8-4fa2-bdac-2cd49a5f5501"},"source":["!wget https://raw.githubusercontent.com/Alireza-Akhavan/SRU-deeplearning-workshop/master/dataset.py\n","!mkdir dataset\n","!wget https://github.com/Alireza-Akhavan/SRU-deeplearning-workshop/raw/master/dataset/Data_hoda_full.mat -P dataset"],"execution_count":1,"outputs":[{"output_type":"stream","text":["--2020-09-18 08:10:41--  https://raw.githubusercontent.com/Alireza-Akhavan/SRU-deeplearning-workshop/master/dataset.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 929 [text/plain]\n","Saving to: ‘dataset.py’\n","\n","\rdataset.py            0%[                    ]       0  --.-KB/s               \rdataset.py          100%[===================>]     929  --.-KB/s    in 0s      \n","\n","2020-09-18 08:10:41 (44.7 MB/s) - ‘dataset.py’ saved [929/929]\n","\n","--2020-09-18 08:10:42--  https://github.com/Alireza-Akhavan/SRU-deeplearning-workshop/raw/master/dataset/Data_hoda_full.mat\n","Resolving github.com (github.com)... 140.82.114.4\n","Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/Alireza-Akhavan/SRU-deeplearning-workshop/master/dataset/Data_hoda_full.mat [following]\n","--2020-09-18 08:10:42--  https://raw.githubusercontent.com/Alireza-Akhavan/SRU-deeplearning-workshop/master/dataset/Data_hoda_full.mat\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3989009 (3.8M) [application/octet-stream]\n","Saving to: ‘dataset/Data_hoda_full.mat’\n","\n","Data_hoda_full.mat  100%[===================>]   3.80M  12.8MB/s    in 0.3s    \n","\n","2020-09-18 08:10:43 (12.8 MB/s) - ‘dataset/Data_hoda_full.mat’ saved [3989009/3989009]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6T8jJnh7P-QQ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600416647487,"user_tz":-270,"elapsed":2623,"user":{"displayName":"atousa n","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgasGtCWD--Qe32bcBkROLnnOpS3LnxbN_U86POOw=s64","userId":"10426377340166915620"}}},"source":["%load_ext tensorboard\n","\n","!rm -rf ./logs/ \n","\n","import tensorflow as tf"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"HzWtWzUmQFb2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600418955229,"user_tz":-270,"elapsed":1522,"user":{"displayName":"atousa n","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgasGtCWD--Qe32bcBkROLnnOpS3LnxbN_U86POOw=s64","userId":"10426377340166915620"}}},"source":["class myCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs={}):\n","        print(logs)\n","        if(logs.get('val_accuracy')>0.75):\n","            print(\"\\nReached 75% accuracy so cancelling training!\")\n","            self.model.stop_training = True\n","            \n","callbacks = myCallback()"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"26JqZ2qdQArn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"executionInfo":{"status":"ok","timestamp":1600420922194,"user_tz":-270,"elapsed":5234,"user":{"displayName":"atousa n","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgasGtCWD--Qe32bcBkROLnnOpS3LnxbN_U86POOw=s64","userId":"10426377340166915620"}},"outputId":"5518330c-d645-42d4-e39f-23911be3878e"},"source":["# 1. Import libraries and modules\n","import keras\n","from keras import layers\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation\n","import numpy as np\n","from dataset import load_hoda\n","import matplotlib.pyplot as plt\n","\n","np.random.seed(123)  # for reproducibility\n","\n","# Load pre-shuffled HODA data into train and test sets\n","x_train_original, y_train_original, x_test_original, y_test_original = load_hoda(\n","                                                                        training_sample_size=3500,\n","                                                                        test_sample_size=400,size=28)\n","\n","# Preprocess input data\n","''' 3.1: input data in numpy array format'''\n","x_train = np.array(x_train_original)\n","x_test = np.array(x_test_original)\n","'''3.2 normalize our data values to the range [0, 1]'''\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","\n","# Reshape to original image shape (n x 784)  ==> (n x 28 x 28 x 1)\n","x_train = x_train.reshape(-1,28,28,1)\n","x_test = x_test.reshape(-1,28,28,1)\n","\n","\n","# 4. Preprocess class labels\n","y_train = keras.utils.to_categorical(y_train_original, num_classes=10)\n","y_test = keras.utils.to_categorical(y_test_original, num_classes=10)\n","\n","\n","# test and validation set\n","x_val = x_test[:200]\n","x_test = x_test[200:]\n","y_val = y_test[:200]\n","y_test = y_test[200:]\n","\n","# 5. Define model architecture\n","model = Sequential()\n","model.add(layers.Conv2D(32, (3, 3), activation='relu',\n","                        input_shape=(28, 28, 1)))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","model.add(layers.Flatten())\n","model.add(layers.Dense(64, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(layers.Dense(10, activation='softmax'))\n","\n","# 6. Compile model\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['accuracy'])\n","\n","\n","# 7. Fit model on training data\n","history = model.fit(x_train, y_train,\n","          epochs=200, batch_size=256, validation_data = (x_val, y_val), callbacks=[callbacks])"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Epoch 1/200\n","14/14 [==============================] - ETA: 0s - loss: 1.8371 - accuracy: 0.3646{'loss': 1.837119460105896, 'accuracy': 0.3645714223384857, 'val_loss': 0.9897627234458923, 'val_accuracy': 0.824999988079071}\n","\n","Reached 75% accuracy so cancelling training!\n","14/14 [==============================] - 2s 178ms/step - loss: 1.8371 - accuracy: 0.3646 - val_loss: 0.9898 - val_accuracy: 0.8250\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8z1tXG28gghe","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}